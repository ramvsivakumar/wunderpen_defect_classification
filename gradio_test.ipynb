{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XZn4JDo5djcgUBAgfle5xUOzF09OCJ7s",
      "authorship_tag": "ABX9TyNXXUUGwVyLAZsfH/DWIc/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/ramvsiva/134baef174e7aa178c023b2c5d64e90a/gradio_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio==3.50.0 transformers"
      ],
      "metadata": {
        "id": "VEmWLQ1sBM2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xen-yMGf-7qy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "455099d9-5711-4fba-9f76-9cda774a5917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: You are using gradio version 3.50.0, however version 4.29.0 is available, please upgrade.\n",
            "--------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/image.py:193: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Image(...)` instead of `return gr.Image.update(...)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/components/textbox.py:163: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Textbox(...)` instead of `return gr.Textbox.update(...)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://db51047b1aa6291686.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://db51047b1aa6291686.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from transformers import ViTForImageClassification\n",
        "\n",
        "\n",
        "model_path = '/content/drive/MyDrive/berlin/model/'\n",
        "num_labels = 12\n",
        "test_images_dir = '/content/drive/MyDrive/berlin/test_images/Prodfile_Job_10_Envelope'\n",
        "support_images_dir = '/content/drive/MyDrive/berlin/test_images/Gcode_Images'\n",
        "def is_image_file(filename):\n",
        "    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))\n",
        "\n",
        "test_images = sorted([file for file in os.listdir(test_images_dir) if is_image_file(file)])\n",
        "support_images = sorted([file for file in os.listdir(support_images_dir) if is_image_file(file)])\n",
        "\n",
        "\n",
        "image_index = -1\n",
        "\n",
        "\n",
        "def load_model(model_path, num_labels):\n",
        "    model = ViTForImageClassification.from_pretrained(model_path, num_labels=num_labels)\n",
        "    model.eval()\n",
        "    model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    return model\n",
        "\n",
        "\n",
        "model = load_model(model_path, num_labels)\n",
        "\n",
        "\n",
        "def process_image(image):\n",
        "    if isinstance(image, np.ndarray):\n",
        "        image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "\n",
        "def predict_image(model, processed_image):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(processed_image.to(model.device))\n",
        "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        confidence, predicted_class = torch.max(probabilities, dim=1)\n",
        "    return predicted_class.item(), confidence.item()\n",
        "\n",
        "\n",
        "def update_display(test_image_path, support_image_path, target_filename, support_filename):\n",
        "    test_image = Image.open(test_image_path)\n",
        "    support_image = Image.open(support_image_path)\n",
        "    return test_image, support_image, target_filename, support_filename\n",
        "\n",
        "\n",
        "def predict(source_choice, test_image, upload_image):\n",
        "    if source_choice == \"Upload\":\n",
        "        processed_image = process_image(upload_image)\n",
        "    else:\n",
        "        processed_image = process_image(test_image)\n",
        "    predicted_class, confidence = predict_image(model, processed_image)\n",
        "    return f\"Class: C{predicted_class}\", f\"Confidence: {confidence:.2%}\"\n",
        "\n",
        "\n",
        "def next_image():\n",
        "    global image_index\n",
        "    image_index = (image_index + 1) % len(test_images)\n",
        "    return update_display(\n",
        "        os.path.join(test_images_dir, test_images[image_index]),\n",
        "        os.path.join(support_images_dir, support_images[image_index]),\n",
        "        test_images[image_index],\n",
        "        support_images[image_index]\n",
        "    )\n",
        "\n",
        "\n",
        "def previous_image():\n",
        "    global image_index\n",
        "    image_index = (image_index - 1) % len(test_images)\n",
        "    test_image_filename = os.path.join(test_images_dir, test_images[image_index])\n",
        "    support_image_filename = os.path.join(support_images_dir, support_images[image_index])\n",
        "\n",
        "    return update_display(\n",
        "        test_image_filename,\n",
        "        support_image_filename,\n",
        "        test_images[image_index],\n",
        "        support_images[image_index]\n",
        "    )\n",
        "\n",
        "\n",
        "def get_initial_images():\n",
        "    global image_index\n",
        "    test_image_path = os.path.join(test_images_dir, test_images[image_index])\n",
        "    support_image_path = os.path.join(support_images_dir, support_images[image_index])\n",
        "    test_image = Image.open(test_image_path)\n",
        "    support_image = Image.open(support_image_path)\n",
        "    return test_image, support_image, test_images[image_index], support_images[image_index]\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    source_selector = gr.Radio(choices=[\"Upload\", \"Test Stack\"], label=\"Select Image Source\", value=\"Test Stack\")\n",
        "    with gr.Row():\n",
        "        test_image_label = gr.Textbox(label=\"Test Image Filename\", interactive=False)\n",
        "        support_image_label = gr.Textbox(label=\"Support Image Filename\", interactive=False)\n",
        "    with gr.Row():\n",
        "        test_image = gr.Image(tool='editor', min_width=80, type='pil', interactive=False, label=\"Test Image\")\n",
        "        support_image = gr.Image(tool='editor', min_width=80, type='pil', interactive=False, label=\"Support Image\")\n",
        "    with gr.Row():\n",
        "        gr.Button(\"Previous\").click(previous_image, outputs=[test_image, support_image, test_image_label, support_image_label])\n",
        "        gr.Button(\"Next\").click(next_image, outputs=[test_image, support_image, test_image_label, support_image_label])\n",
        "    upload_image = gr.Image(tool='editor', type='pil', interactive=True, label=\"Upload Image for Prediction\")\n",
        "    predict_button = gr.Button(\"Predict\")\n",
        "    with gr.Row():\n",
        "        predicted_class = gr.Textbox(label=\"Predicted Class\")\n",
        "        prediction_score = gr.Textbox(label=\"Prediction Confidence\")\n",
        "    predict_button.click(predict, inputs=[source_selector, test_image, upload_image], outputs=[predicted_class, prediction_score])\n",
        "\n",
        "    # Load initial images on interface start\n",
        "    initial_images = get_initial_images()\n",
        "    test_image.update(initial_images[0])\n",
        "    support_image.update(initial_images[1])\n",
        "    test_image_label.update(initial_images[2])\n",
        "    support_image_label.update(initial_images[3])\n",
        "\n",
        "demo.launch(server_name='0.0.0.0', server_port=8070, share=True)\n",
        "\n"
      ]
    }
  ]
}